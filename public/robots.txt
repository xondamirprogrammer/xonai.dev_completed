# World-Class SEO Robots.txt Configuration
# Enhanced crawling directives for maximum search engine visibility

User-agent: *
Allow: /
Disallow: /admin/
Disallow: /api/
Disallow: /.env
Disallow: /tmp/
Disallow: /*?*utm_source=
Disallow: /*?*utm_medium=
Disallow: /*?*utm_campaign=
Disallow: /*?*fbclid=
Disallow: /*?*gclid=

# Enhanced Google-specific directives
User-agent: Googlebot
Allow: /
Disallow: /admin/
Disallow: /api/
Crawl-delay: 0
Request-rate: 1/1s

# Bing optimization
User-agent: bingbot
Allow: /
Crawl-delay: 1

# Yandex optimization  
User-agent: YandexBot
Allow: /
Crawl-delay: 2

# Social media crawlers
User-agent: facebookexternalhit
Allow: /

User-agent: Twitterbot
Allow: /

User-agent: LinkedInBot
Allow: /

# Sitemaps (Enhanced)
Sitemap: https://xonai.dev/sitemap.xml
Sitemap: https://xonai.dev/sitemap-pages.xml
Sitemap: https://xonai.dev/sitemap-services.xml

# Host directive
Host: https://xonai.dev

# Crawl optimization
Crawl-delay: 1